{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Molter73/proyecto-computacion-1/blob/mauro%2Fnotebooks/training/Evaluaci%C3%B3n_de_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown==v4.6.3\n",
        "\n",
        "![ ! -d /content/SemEval2024-Task8 ] && gdown --folder https://drive.google.com/drive/folders/14DulzxuH5TDhXtviRVXsH5e2JTY2POLi"
      ],
      "metadata": {
        "id": "qvxZ9sH5FL9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kILQFi6Jw9A0"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl2_I4t7JuFG"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz4v-MZ8jbUH"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBW8t4_SjdxX"
      },
      "outputs": [],
      "source": [
        "# read dataset function\n",
        "def read_dataset(inFile):\n",
        "    print(\"\\nReading:\", inFile)\n",
        "    data =  pd.read_json(inFile, lines=True)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF17EiI7jvI-"
      },
      "outputs": [],
      "source": [
        "# data paths and config\n",
        "inTrain = '/content/SemEval2024-Task8/SubtaskA/subtaskA_train_monolingual.jsonl'\n",
        "inTest = '/content/SemEval2024-Task8/SubtaskA/subtaskA_dev_monolingual.jsonl'\n",
        "inDatasetTest = '/content/mount/dataset.jsonl'\n",
        "\n",
        "max_instances_per_class = 20000\n",
        "max_features = 5000 # maximum number of features extracted for our instances\n",
        "random_seed = 777 # set random seed for reproducibility\n",
        "id2label = {0: \"human\", 1: \"machine\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YD-29tskP93"
      },
      "outputs": [],
      "source": [
        "# read dataset\n",
        "train_df = read_dataset(inTrain)\n",
        "test_df = read_dataset(inTest)\n",
        "dataset_df = read_dataset(inDatasetTest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33j_uuSjBS17"
      },
      "outputs": [],
      "source": [
        "#Establecemos el número de instancias presentes\n",
        "instancias_humanas = len(train_df[train_df['label'] == 0])\n",
        "instancias_ia =  len(train_df[train_df['label'] == 1])\n",
        "instancias_dataset = len(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzbprNdK6_nb"
      },
      "outputs": [],
      "source": [
        "#Sumamos las instancias y realizamos la longitud media\n",
        "suma_longitudes_humanos = train_df[train_df['label'] == 0]['text'].apply(len).sum()\n",
        "longitud_media_humanos = suma_longitudes_humanos / instancias_humanas\n",
        "\n",
        "suma_longitudes_generados = train_df[train_df['label'] == 1]['text'].apply(len).sum()\n",
        "longitud_media_generado = suma_longitudes_generados / instancias_ia"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imprimimos la Tabla de Estadísticas\n",
        "print('Número de instancias en el dataset:\\t\\t\\t\\t', instancias_dataset)\n",
        "print('Número de instancias humanas:\\t\\t\\t\\t\\t', instancias_humanas)\n",
        "print('Número de instancias generadas:\\t\\t\\t\\t\\t', instancias_ia)\n",
        "print('Longitud media en caracteres de las instancias humanas:\\t\\t', longitud_media_humanos)\n",
        "print('Longitud media en caracteres de las instancias generadas:\\t', longitud_media_generado)"
      ],
      "metadata": {
        "id": "I0kkwHapTK5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_text_lengths(df):\n",
        "  #Establecemos el número de instancias presentes\n",
        "  instancias_humanas = len(df[df['label'] == 0])\n",
        "  instancias_ia =  len(df[df['label'] == 1])\n",
        "  instancias_dataset = len(df)\n",
        "\n",
        "  #Sumamos las instancias y realizamos la longitud media\n",
        "  suma_longitudes_humanos = df[df['label'] == 0]['text'].apply(len).sum()\n",
        "  longitud_media_humanos = suma_longitudes_humanos / instancias_humanas\n",
        "\n",
        "  suma_longitudes_generados = df[df['label'] == 1]['text'].apply(len).sum()\n",
        "  longitud_media_generado = suma_longitudes_generados / instancias_ia\n",
        "\n",
        "  return (longitud_media_humanos, longitud_media_generado)"
      ],
      "metadata": {
        "id": "53atX_xSRnJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrjefNsJkJaP"
      },
      "outputs": [],
      "source": [
        "from itertools import count\n",
        "\n",
        "def balance_text_lengths(df):\n",
        "  starting_rows = len(df.index)\n",
        "  # downsample training data to train faster\n",
        "  balanced_df = df.groupby(\"label\").sample(n=max_instances_per_class, random_state=random_seed)\n",
        "  human_length, machine_length = get_text_lengths(balanced_df)\n",
        "\n",
        "  while human_length > machine_length * 1.05:\n",
        "    cutoff = (df[df['label'] == 0]['text'].apply(len).max() + machine_length) / 2\n",
        "    df = df.drop(df[(df['text'].map(len) > cutoff) & (df['label'] == 0)].index)\n",
        "\n",
        "    if starting_rows == len(df.index):\n",
        "      print(\"No more rows to remove\")\n",
        "      return balanced_df\n",
        "\n",
        "    human_length, machine_length = get_text_lengths(balanced_df)\n",
        "    balanced_df = df.groupby(\"label\").sample(n=max_instances_per_class, random_state=random_seed)\n",
        "    human_length, machine_length = get_text_lengths(balanced_df)\n",
        "\n",
        "  return balanced_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = balance_text_lengths(train_df)"
      ],
      "metadata": {
        "id": "veeztoJaS19G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Establecemos el número de instancias presentes\n",
        "instancias_humanas = len(train_df[train_df['label'] == 0])\n",
        "instancias_ia =  len(train_df[train_df['label'] == 1])\n",
        "instancias_dataset = len(train_df)"
      ],
      "metadata": {
        "id": "XNOs7PTlSxN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sumamos las instancias y realizamos la longitud media\n",
        "suma_longitudes_humanos = train_df[train_df['label'] == 0]['text'].apply(len).sum()\n",
        "longitud_media_humanos = suma_longitudes_humanos / instancias_humanas\n",
        "\n",
        "suma_longitudes_generados = train_df[train_df['label'] == 1]['text'].apply(len).sum()\n",
        "longitud_media_generado = suma_longitudes_generados / instancias_ia"
      ],
      "metadata": {
        "id": "DC684XC-S0dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuU16cOQ7QQx"
      },
      "outputs": [],
      "source": [
        "#Imprimimos la Tabla de Estadísticas\n",
        "print('Número de instancias en el dataset:\\t\\t\\t\\t', instancias_dataset)\n",
        "print('Número de instancias humanas:\\t\\t\\t\\t\\t', instancias_humanas)\n",
        "print('Número de instancias generadas:\\t\\t\\t\\t\\t', instancias_ia)\n",
        "print('Longitud media en caracteres de las instancias humanas:\\t\\t', longitud_media_humanos)\n",
        "print('Longitud media en caracteres de las instancias generadas:\\t', longitud_media_generado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHdZ48gBlJB8"
      },
      "outputs": [],
      "source": [
        "# vectorize data: extract features from our data (from text to numeric vectors)\n",
        "vectorizer = TfidfVectorizer(max_features=max_features, stop_words=\"english\", ngram_range=(1,1))\n",
        "X_train = vectorizer.fit_transform(train_df[\"text\"])\n",
        "X_test = vectorizer.transform(test_df[\"text\"])\n",
        "X_dataset = vectorizer.transform(dataset_df[\"text\"])\n",
        "\n",
        "# print({k: v for k, v in sorted(vectorizer.vocabulary_.items(), key=lambda item: item[1], reverse=True)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2jZYOPLmFcW"
      },
      "outputs": [],
      "source": [
        "# vectorize labels : from text to numeric vectors\n",
        "le = LabelEncoder()\n",
        "Y_train = le.fit_transform(train_df[\"label\"])\n",
        "Y_test = le.transform(test_df[\"label\"])\n",
        "Y_dataset = le.transform(dataset_df[\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igOJBWhl8-tg"
      },
      "outputs": [],
      "source": [
        "#Imprimimos Tabla de Estadísticas\n",
        "print('Número de instancias en el training:\\t\\t',len(train_df))\n",
        "print('Número de instancias en el test:\\t\\t',len(test_df))\n",
        "print('Número de instancias en el dataset:\\t\\t',len(dataset_df))\n",
        "print('Número de instancias humanas en el training:\\t',len(train_df[train_df['label'] == 0]))\n",
        "print('Número de instancias generadas en el training:\\t',len(train_df[train_df['label'] == 1]))\n",
        "print('Número de instancias humanas en el test:\\t',len(test_df[test_df['label'] == 0]))\n",
        "print('Número de instancias generadas en el test:\\t',len(test_df[test_df['label'] == 1]))\n",
        "print('Número de instancias humanas en el dataset:\\t',len(dataset_df[dataset_df['label'] == 0]))\n",
        "print('Número de instancias generadas en el dataset:\\t',len(dataset_df[dataset_df['label'] == 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQ7sMUu_td04"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import all_estimators\n",
        "from sklearn.base import ClassifierMixin\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from heapq import heappush, nlargest\n",
        "import multiprocessing\n",
        "\n",
        "best_score = float('-inf')\n",
        "best_model = None\n",
        "best_dataset_score = float('-inf')\n",
        "best_dataset_model = None\n",
        "\n",
        "test_heap = []\n",
        "dataset_heap = []\n",
        "priority = 0\n",
        "\n",
        "from joblib import parallel_backend\n",
        "\n",
        "with parallel_backend('threading', n_jobs=multiprocessing.cpu_count()):\n",
        "\n",
        "  for name, ClassifierClass in all_estimators(type_filter='classifier'):\n",
        "        if issubclass(ClassifierClass, ClassifierMixin) and hasattr(ClassifierClass, 'fit'):\n",
        "          try:\n",
        "              regressor = ClassifierClass()\n",
        "              regressor.fit(X_train, Y_train)\n",
        "\n",
        "              y_pred = regressor.predict(X_test)\n",
        "              score = f1_score(Y_test, y_pred, average=\"macro\")\n",
        "              if score > best_score:\n",
        "                  best_score = score\n",
        "                  best_model = regressor\n",
        "              print(f\"Model: {name} Macro F1: {score}\")\n",
        "              print(classification_report(Y_test, y_pred))\n",
        "              heappush(test_heap, (score, priority, regressor))\n",
        "\n",
        "              y_pred = regressor.predict(X_dataset)\n",
        "              score = f1_score(Y_dataset, y_pred, average=\"macro\")\n",
        "              if score > best_dataset_score:\n",
        "                  best_dataset_score = score\n",
        "                  best_dataset_model = regressor\n",
        "              print(f\"Model: {name} Dataset Macro F1: {score}\")\n",
        "              print(classification_report(Y_dataset, y_pred))\n",
        "              heappush(dataset_heap, (score, priority, regressor))\n",
        "              priority += 1\n",
        "\n",
        "          except Exception as e:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best models for test:\")\n",
        "for score, _, model in nlargest(5, test_heap):\n",
        "  print(f\"{model.__class__.__name__}, score: {score}\")"
      ],
      "metadata": {
        "id": "WmO4y4RxYaB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Best models for dataset:\")\n",
        "for score, _, model in nlargest(5, dataset_heap):\n",
        "  print(f\"{model.__class__.__name__}, score: {score}\")"
      ],
      "metadata": {
        "id": "APBoY0XwXU4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "owzlTsdF1n9j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}